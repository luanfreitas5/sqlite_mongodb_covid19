{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import year, col, to_date, date_format, regexp_replace\n",
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de caminhos para os arquivos CSV\n",
    "datasets = [f'datasets/part-0000{i}-aca9a996-ed21-4acc-b0e0-8c92f4b8f369.c000.csv' for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame no inicio possui 8503892 regristos.\n",
      "O DataFrame apos o tratamento de dados possui 8503885 regristos.\n"
     ]
    }
   ],
   "source": [
    "# Cria uma SparkSession configurada para trabalhar com SQL e especifica parâmetros de memória e núcleos de processamento\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SQL\") \\\n",
    "    .config(\"spark.jars\", \"drivers/sqlite-jdbc-3.46.0.0.jar\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "\n",
    "# Ler e combinar todos os arquivos CSV em um DataFrame, inferindo o esquema, definindo o cabeçalho, delimitador e formato de data\n",
    "df = spark.read.csv(datasets, header=True, inferSchema=True, sep=';', encoding=\"utf-8\", dateFormat='%d/%m/%Y')\n",
    "\n",
    "# Conta o número de linhas do DataFrame\n",
    "numero_de_linhas = df.count()\n",
    "print(f\"O DataFrame no inicio possui {numero_de_linhas} registros.\")\n",
    "\n",
    "# Remove linhas duplicadas com base na coluna 'document_id'\n",
    "df = df.dropDuplicates(['document_id'])\n",
    "\n",
    "# Preenche valores ausentes em colunas específicas com valores padrão dependendo do tipo de dado\n",
    "for col_name, dtype in df.dtypes:\n",
    "    if dtype == \"int\":\n",
    "        df = df.fillna({col_name : 0})\n",
    "    elif dtype == \"double\":\n",
    "        df = df.fillna({col_name : 0.0})\n",
    "    elif dtype == \"string\":\n",
    "        df = df.fillna({col_name : 'SEM INFORMACAO'})\n",
    "    elif dtype == \"boolean\":\n",
    "        df = df.fillna({col_name : False})\n",
    "    elif dtype == \"timestamp\":\n",
    "        df = df.fillna({col_name : '1900-01-01'})\n",
    "    elif dtype == \"date\":\n",
    "        df = df.fillna({col_name : '1900-01-01'})\n",
    "\n",
    "# Converte as colunas de data para o formato adequado\n",
    "df = df.withColumn(\"vacina_dataAplicacao\", to_date(col(\"vacina_dataAplicacao\"), \"dd/MM/yyyy\"))\n",
    "df = df.withColumn(\"paciente_dataNascimento\", to_date(col(\"paciente_dataNascimento\"), \"dd/MM/yyyy\"))\n",
    "\n",
    "# Adiciona uma coluna 'ano' extraída da data de aplicação da vacina\n",
    "df = df.withColumn(\"ano\", year(df[\"vacina_dataAplicacao\"]))\n",
    "\n",
    "# Ordena o DataFrame pela data de aplicação da vacina\n",
    "df = df.orderBy(\"vacina_dataAplicacao\")\n",
    "\n",
    "# Filtra os registros para manter apenas aqueles com a data de aplicação da vacina entre 2021 e 2024\n",
    "df = df.filter((year(df['vacina_dataAplicacao']) >= 2021) & (year(df['vacina_dataAplicacao']) <= 2024))\n",
    "\n",
    "# Converte as colunas de data para o formato 'yyyy-MM-dd'\n",
    "df = df.withColumn(\"vacina_dataAplicacao\", date_format(col(\"vacina_dataAplicacao\"), \"yyyy-MM-dd\"))\n",
    "df = df.withColumn(\"paciente_dataNascimento\", date_format(col(\"paciente_dataNascimento\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "# Remove a coluna 'ano' que foi usada apenas para filtragem\n",
    "df = df.drop(\"ano\")\n",
    "\n",
    "# Conta o número de linhas do DataFrame após o tratamento de dados\n",
    "numero_de_linhas = df.count()\n",
    "print(f\"O DataFrame apos o tratamento de dados possui {numero_de_linhas} registros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigir valores \"PFIZER - PEDI?TRICA\" para \"PFIZER - PEDIÁTRICA\"\n",
    "df = df.withColumn(\n",
    "    \"vacina_fabricante_nome\",\n",
    "    regexp_replace(\"vacina_fabricante_nome\", \"PFIZER - PEDI\\\\?TRICA\", \"PFIZER - PEDIÁTRICA\")\n",
    ")\n",
    "\n",
    "# Corrigir valores \"Pendente Identifica??o\" para \"Pendente Identificação\"\n",
    "df = df.withColumn(\n",
    "    \"vacina_fabricante_nome\",\n",
    "    regexp_replace(\"vacina_fabricante_nome\", \"Pendente Identifica\\\\?\\\\?o\", \"Pendente Identificação\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define nome da tabela para o banco de dados\n",
    "nomeTabela = 'vacinacao_covid_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduz o número de partições do DataFrame para 1 antes de escrever no banco de dados\n",
    "df.coalesce(1).write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:sqlite:datasets/vacinacao_covid_df.db\") \\\n",
    "    .option(\"dbtable\", nomeTabela) \\\n",
    "    .option(\"driver\", \"org.sqlite.JDBC\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
